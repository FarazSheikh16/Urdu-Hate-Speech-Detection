{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "v6zmbz7IuQ1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/final_combined_mobandus.csv\")\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "9NCLI3E0uUig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from keras.optimizers import Adam , SGD"
      ],
      "metadata": {
        "id": "IwrKQY7lWBrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Text'])\n",
        "X = tokenizer.texts_to_sequences(df['Text'])\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "JCgW2pAnWFSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an Embedding layer\n",
        "embedding_dim = 50\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=X.shape[1]))\n",
        "\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(100, return_sequences=False))\n",
        "model.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Add a Dense layer for classification\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "# Output model summary\n",
        "model.summary()\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xn0j_ZWvgSp",
        "outputId": "83ff7044-2a3b-4c4f-ef7e-91f662e1d902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 72, 50)            1136050   \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 72, 50)            20200     \n",
            "                                                                 \n",
            " lstm_26 (LSTM)              (None, 100)               60400     \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1216953 (4.64 MB)\n",
            "Trainable params: 1216953 (4.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 16s 68ms/step - loss: 0.9711 - accuracy: 0.5189 - val_loss: 0.9000 - val_accuracy: 0.4852\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.7627 - accuracy: 0.6694 - val_loss: 0.6140 - val_accuracy: 0.7419\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.5199 - accuracy: 0.8070 - val_loss: 0.5239 - val_accuracy: 0.8307\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 13s 67ms/step - loss: 0.4235 - accuracy: 0.8479 - val_loss: 0.4709 - val_accuracy: 0.8336\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.3493 - accuracy: 0.8816 - val_loss: 0.5061 - val_accuracy: 0.8096\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 0.2865 - accuracy: 0.9070 - val_loss: 0.4815 - val_accuracy: 0.8434\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 0.2413 - accuracy: 0.9222 - val_loss: 0.5057 - val_accuracy: 0.8364\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 13s 65ms/step - loss: 0.2060 - accuracy: 0.9356 - val_loss: 0.5402 - val_accuracy: 0.8364\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 13s 66ms/step - loss: 0.1741 - accuracy: 0.9431 - val_loss: 0.6284 - val_accuracy: 0.8364\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 13s 64ms/step - loss: 0.1484 - accuracy: 0.9525 - val_loss: 0.6697 - val_accuracy: 0.8265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3eca18fe50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "# Train the model\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7-rVkjdxFWM",
        "outputId": "7c87d73e-1a4f-4fd9-d66f-ebe4bed00bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56/56 [==============================] - 2s 20ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.86      0.79       662\n",
            "           1       0.76      0.59      0.67       212\n",
            "           2       0.91      0.83      0.87       899\n",
            "\n",
            "    accuracy                           0.82      1773\n",
            "   macro avg       0.80      0.76      0.78      1773\n",
            "weighted avg       0.82      0.82      0.82      1773\n",
            "\n",
            "Accuracy: 0.8161308516638466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['Text'])\n",
        "X = tokenizer.texts_to_sequences(df['Text'])\n",
        "X = pad_sequences(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Specify the learning rate\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add an Embedding layer\n",
        "embedding_dim = 50\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=X.shape[1]))\n",
        "\n",
        "# Add LSTM layers\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(100, return_sequences=False))\n",
        "model.add(Dropout(0.3))  # Adding dropout for regularization\n",
        "\n",
        "# Add a Dense layer for classification\n",
        "model.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "# Output model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model with a specified learning rate\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v9Ktlkr0v0s",
        "outputId": "ce62724c-c684-43c4-ca61-4433b5957f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_21 (Embedding)    (None, 72, 50)            1136050   \n",
            "                                                                 \n",
            " lstm_37 (LSTM)              (None, 72, 50)            20200     \n",
            "                                                                 \n",
            " lstm_38 (LSTM)              (None, 100)               60400     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 3)                 303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1216953 (4.64 MB)\n",
            "Trainable params: 1216953 (4.64 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "309/309 [==============================] - 25s 73ms/step - loss: 1.0386 - accuracy: 0.4519 - val_loss: 0.9325 - val_accuracy: 0.5328\n",
            "Epoch 2/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.8153 - accuracy: 0.6090 - val_loss: 0.7994 - val_accuracy: 0.5995\n",
            "Epoch 3/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.6930 - accuracy: 0.6890 - val_loss: 0.7592 - val_accuracy: 0.6633\n",
            "Epoch 4/10\n",
            "309/309 [==============================] - 22s 70ms/step - loss: 0.5884 - accuracy: 0.7606 - val_loss: 0.7362 - val_accuracy: 0.6998\n",
            "Epoch 5/10\n",
            "309/309 [==============================] - 21s 67ms/step - loss: 0.4993 - accuracy: 0.8077 - val_loss: 0.7470 - val_accuracy: 0.7181\n",
            "Epoch 6/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.4256 - accuracy: 0.8378 - val_loss: 0.7997 - val_accuracy: 0.7016\n",
            "Epoch 7/10\n",
            "309/309 [==============================] - 21s 68ms/step - loss: 0.3634 - accuracy: 0.8678 - val_loss: 0.8431 - val_accuracy: 0.6953\n",
            "Epoch 8/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.3072 - accuracy: 0.8910 - val_loss: 0.9052 - val_accuracy: 0.6898\n",
            "Epoch 9/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.2632 - accuracy: 0.9098 - val_loss: 1.0078 - val_accuracy: 0.6816\n",
            "Epoch 10/10\n",
            "309/309 [==============================] - 21s 69ms/step - loss: 0.2245 - accuracy: 0.9260 - val_loss: 1.0914 - val_accuracy: 0.6807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a3ebc7acd30>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "# Train the model\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_true, y_pred_classes)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pjANx445aZy",
        "outputId": "e1662878-a960-401c-be97-c05ebd1e95a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86/86 [==============================] - 2s 18ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.62      0.62       905\n",
            "           1       0.66      0.62      0.64       891\n",
            "           2       0.71      0.75      0.73       944\n",
            "\n",
            "    accuracy                           0.67      2740\n",
            "   macro avg       0.66      0.66      0.66      2740\n",
            "weighted avg       0.66      0.67      0.66      2740\n",
            "\n",
            "Accuracy: 0.6656934306569343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "riMg1FAB8rzm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}